{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx2txt\n",
    "import regex as re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=docx2txt.process(\"12+.docx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sandeep.dasc1@gmail.com'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(\"[A-Za-z0-9_\\.\\-]+[@][a-z]+[\\.][a-z]{2,3}\",text)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=os.listdir(r\"Resumes/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmail_id=[]\n",
    "for i in (path):\n",
    "    text2=docx2txt.process(r\"Resumes/\"+i)\n",
    "\n",
    "    if (len(re.findall(\"[A-Za-z0-9_\\.\\-]+[@][a-z]+[\\.][a-z]{2,3}\",text2)))>0:\n",
    "        gmail_id_found=(re.findall(\"[A-Za-z0-9_\\.\\-]+[@][a-z]+[\\.][a-z]{2,3}\",text2))\n",
    "        if (len(gmail_id_found)>1):\n",
    "            del(gmail_id_found[1])\n",
    "            gmail_id.extend(gmail_id_found)\n",
    "        else:\n",
    "            gmail_id.extend(gmail_id_found)\n",
    "\n",
    "    else:\n",
    "        gmail_id.append(np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan, 'sandeep.dasc1@gmail.com', nan, nan, nan, nan]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(gmail_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(re.findall(\"[A-Za-z0-9_\\.\\-]+[@][a-z]+[\\.][a-z]{2,3}\",text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# www.linkedin.com/in/pulavarthy-s-321a92152/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkedin_id=[]\n",
    "for i in (path):\n",
    "    text2=docx2txt.process(r\"Resumes/\"+i)\n",
    "\n",
    "    if (len(re.findall(\"\\w{3}[\\.]\\w{8}[\\.]\\w{3}[\\/]\\w+[\\/]\\w+[\\-]\\w+[\\-]\\w+[\\/]\",text2)))>0:\n",
    "        linkedin_id_found=(re.findall(\"\\w{3}[\\.]\\w{8}[\\.]\\w{3}[\\/]\\w+[\\/]\\w+[\\-]\\w+[\\-]\\w+[\\/]\",text2))\n",
    "        if (len(linkedin_id_found)>1):\n",
    "            del(linkedin_id_found[1])\n",
    "            linkedin_id.extend(linkedin_id_found)\n",
    "        else:\n",
    "            linkedin_id.extend(linkedin_id_found)\n",
    "\n",
    "    else:\n",
    "        linkedin_id.append(np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['www.linkedin.com/in/pulavarthy-s-321a92152/',\n",
       " 'www.linkedin.com/in/pulavarthy-s-321a92152/']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(\"\\w{3}[\\.]\\w{8}[\\.]\\w{3}[\\/]\\w+[\\/]\\w+[\\-]\\w+[\\-]\\w+[\\/]\",text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# www.linkedin.com/in/pulavarthy-s-321a92152/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan, 'www.linkedin.com/in/pulavarthy-s-321a92152/', nan, nan, nan, nan]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linkedin_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "\n",
      "\t\t    \n",
      "\n",
      "\t\tProfessional Summary:                                       \n",
      "\n",
      "\t\t\n",
      "\n",
      "\tAround 12+ Years of IT experience in PL/SQL, Mainframes and Data Science technologies in Retail, Banking and Healthcare domains\n",
      "\n",
      "\tAround 4+ years of experience as Data Scientist with proven expertise in Machine Learning Algorithms, Deep Learning concepts such as ANN, CNN, RNN and python with libraries such as SKLearn, NumPy, Pandas, Matplotlib, Keras and Tensor Flow.\n",
      "\n",
      "\tAround 1+ year of experience in Pentaho for building files via access to database.\n",
      "\n",
      "\tAround 8+ years of experience in Mainframes platform with expertise in COBOL, JCL, VSAM, SAS, DB2 in both development and Support roles as well as PL-SQL and Oracle Database\n",
      "\n",
      "\tStrong proficiency in application development & quality-driven methodologies.\n",
      "\n",
      "\tExpertise in full SDLC implementation as a key resource in requirement gathering, estimation, design, coding and testing in both Waterfall and Agile Methodology. \n",
      "\n",
      "\tInvolved in sprint planning, creation of user stories, assessment of story points, Agile retrospective meeting.\n",
      "\n",
      "\tExtensively used JIRA tool for tracking user stories and effort\n",
      "\n",
      "\tStrong Leadership skills and rated as a very capable resource in managing team effectively.\n",
      "\n",
      "\tExcellent communication and presentation skills, self-starter, quick learner & team         player\n",
      "\n",
      "\t\n",
      "\n",
      "Technical Skill Set:\n",
      "\n",
      "\n",
      "\n",
      "Programming Languages: \n",
      "\n",
      "Python, Machine Learning (NumPy, Pandas, Matplotlib), Deep Neural Networks (Keras, Tensor Flow), Convolutional Neural Networks, SKlearn Libraries, SPARK Framework, SCALA basics, COBOL, SAS, JCL, VSAM, SQL/PLSQL\n",
      "\n",
      "\n",
      "\n",
      "TOOLS: \n",
      "\n",
      "Anaconda, Jupiter Notebook, Pentaho, JIRA, GitHub, IBM Personal Communication tools like - IBM File Manager, CA-7, SDSF, SAR, IBM File manager, QMF, SPUFI, SUPERC, Endevor, Change Man, ITSM Change Management Tool, \n",
      "\n",
      "\n",
      "\n",
      "Data Base:  DB2, ORACLE\n",
      "\n",
      "\n",
      "\n",
      "Professional Work Experience:\n",
      "\n",
      "\n",
      "\n",
      "Started working in JP Morgan Chase as Senior Application Lead Developer from Oct 2015 till date.\n",
      "\n",
      "Worked as Principle Software Engineer in TESCO HSC from February 2011 till Oct 2015.\n",
      "\n",
      "Worked as Software Engineer in Fidelity India Pvt Ltd from September 2010 till Feb 2011.\n",
      "\n",
      "Worked as a Lead coordinator in IBM India Pvt LTD from Sep 2009 till August 2010.\n",
      "\n",
      "Worked as Developer in IBM India Pvt Ltd from August 2006 Till August 2009.\n",
      "\n",
      "\t\n",
      "\n",
      "\tCertifications and Achievements:\n",
      "\n",
      "\t\n",
      "\n",
      "Won as a runner in ML Theme in TechGig competition.\n",
      "\n",
      "Completed Data science masters in ACADGILD.\n",
      "\n",
      "IBM Certified DB2 Fundamentals.\n",
      "\n",
      "SAS certified base programmer.\n",
      "\n",
      "Certified PAHM (Professional Academy for Healthcare Management) in Year 2007.\n",
      "\n",
      "WellPoint Achievement award for outstanding performance in GL project.\n",
      "\n",
      "Received Value award for smooth and successful closure for Christmas.\n",
      "\n",
      "Involved in CMMI Level 5 recertification program as a Lead and participated in interview with CMMI.\n",
      "\n",
      "\t\n",
      "\n",
      "\tAssignment Summary:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Project # 1\n",
      "\n",
      "\n",
      "\n",
      "Project Name\t: Loan Grader                                                             Role  : Data Scientist\n",
      "\n",
      "Client   \t: JPMC\n",
      "\n",
      "Duration         : Oct 2016 to Sept 2017\n",
      "\n",
      "Environment\t: Python, SKLearn Libraries, Data Visualisation Thru Matplotlib/Seaborn, Machine Learning Algorithms\n",
      "\n",
      "\n",
      "\n",
      "Description: Predict the rating of all customers in order to decide whether he/she is a potential customer to be considered by taking the history of the transactional data which includes banking, card transactions, loans.\n",
      "\n",
      "\n",
      "\n",
      "Responsibilities:\n",
      "\n",
      "Requirement discussions with the clients and also coordinating with Operations team to      understand the manual work around done by the team.\n",
      "\n",
      "Review the estimates for work items, help the team with impact analysis and participate in estimation justification meetings with the clients.\n",
      "\n",
      "Identifying the points from where we need to get data sources and data consolidation process.\n",
      "\n",
      "Involved in Data Pre-processing Techniques such as data cleaning, visualizing the data, identifying outliers and making data ready for Machine Learning Techniques.\n",
      "\n",
      "Machine Learning Algorithms Evaluation.\n",
      "\n",
      "Analyze the results of all algorithm outcomes and deciding the best one\n",
      "\n",
      "Model Deployment process once signoff is in place.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Project # 2\n",
      "\n",
      "\n",
      "\n",
      "Project Name\t: Document Index Processing thru NLP                        Role   : Data Scientist\n",
      "\n",
      "Duration\t: Aug 2017 to Dec 2018\n",
      "\n",
      "Client   \t: JPMC\n",
      "\n",
      "Environment\t: Python, SKLearn Libraries, Data Visualisation Thru Matplotlib/Seaborn, NLP, Machine Learning Algorithms\n",
      "\n",
      "\n",
      "\n",
      "Description: Operations Team manually open several documents as part of their monthly process and decide which type of billing should be done. They take the figures from the respective documents and proceed with the billing process. Using NLP document indexing automated the process of document identification and this has resulted in reducing lot of FTE effort.\n",
      "\n",
      "\n",
      "\n",
      "Responsibilities:\n",
      "\n",
      "Numerous discussions with Operations team and understand the process of work done\n",
      "\n",
      "Engaging with clients and discuss on way of approach for automating the process.\n",
      "\n",
      "Review the estimates for work items, help the team with impact analysis and participate in estimation justification meetings with the clients.\n",
      "\n",
      "Create a platform to get all the documents at one place which is used as an input for Machine Learning Algorithm\n",
      "\n",
      "Data Pre-processing Techniques such as data cleaning, visualizing the data, identifying outliers and making data ready for Machine Learning Techniques.\n",
      "\n",
      "Measure the performance of the algorithms applied and choosing the best one.\n",
      "\n",
      "Model deployment.\n",
      "\n",
      "Project # 3\n",
      "\n",
      "\n",
      "\n",
      "Project Name\t: Mini project on Customer behavior with change in rates\n",
      "\n",
      "Duration\t: 2 months                                                                 Role   : Data Scientist\n",
      "\n",
      "Client   \t: JPMC\t\t\t\t\t\t            \n",
      "\n",
      "Environment\t: Python, SKLearn Libraries, Data Visualisation Thru Matplotlib/Seaborn, Machine Learning Algorithms\n",
      "\n",
      "\n",
      "\n",
      "Description:  As part of this project, prediction of behavior of a customer with the revision of rates as quick grasp for end business users. \n",
      "\n",
      "\n",
      "\n",
      "Responsibilities:\n",
      "\n",
      "Review the estimates for work items, help the team with impact analysis and participate in estimation justification meetings with the clients.\n",
      "\n",
      "Involved in Data Pre-processing Techniques such as data cleaning, visualizing the data, identifying outliers and making data ready for Machine Learning Techniques.\n",
      "\n",
      "Model performance evaluation and presentation to the business users.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Project # 4\n",
      "\n",
      "\n",
      "\n",
      "Project Name\t: Prediction of database spikes                                      Role: Data Scientist\n",
      "\n",
      "Duration\t: 2 months\n",
      "\n",
      "Client   \t: JPMC\n",
      "\n",
      "Environment\t: Python, SKLearn Libraries, Data Visualisation Thru Matplotlib/Seaborn, Machine Learning Algorithms\n",
      "\n",
      "\n",
      "\n",
      "Description: As part of this project, prediction of database spikes for current year based on last 5 years of data.\n",
      "\n",
      "\n",
      "\n",
      "Responsibilities:\n",
      "\n",
      "Review the estimates for work items, help the team with impact analysis and participate in estimation justification meetings with the clients.\n",
      "\n",
      "Involved in Data Pre-processing Techniques such as data cleaning, visualizing the data, identifying outliers and making data ready for Machine Learning Techniques.\n",
      "\n",
      "Model performance evaluation and presentation to the business users.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Project # 5\n",
      "\n",
      "\n",
      "\n",
      "Project Name\t: Consolidated Billing system                       Role: Application Lead Developer\n",
      "\n",
      "Duration\t: Oct 2015 to Sept 2016\n",
      "\n",
      "Client   \t: JPMC\n",
      "\n",
      "Environment\t: Mainframes-COBOL, JCL, DB2,VSAM,CICS,SAS\n",
      "\n",
      "\n",
      "\n",
      "Description: CBS handles all Regular Trades, Fixed Billing, Custodian Billing on a daily basis and monthly basis. Calculates commission and execution charges for all the settled trades. Creates end to end reports and Invoices for all the customers.\n",
      "\n",
      "\n",
      "\n",
      "Responsibilities:\n",
      "\n",
      "Involve in all phases of software development like Analysis, design, coding, testing for development and enhancement work requests (work orders greater than 500 hours).\n",
      "\n",
      "Participation in requirements gathering meeting with clients.\n",
      "\n",
      "Review the estimates for work items, help the team with impact analysis and participate in estimation justification meetings with the clients.\n",
      "\n",
      "Review of all the work artifacts from the team.\n",
      "\n",
      "Providing the test support and fixing all the defects raised.\n",
      "\n",
      "Implementing the changes in production system.\n",
      "\n",
      "Supporting and Monitoring Production batches.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Project # 6\n",
      "\n",
      "\n",
      "\n",
      "Project Name\t   : SAFE, CASH REPORTS                        Role   : Principle Software Engineer \n",
      "\n",
      "Duration\t   : Feb 2011-Oct 2015\n",
      "\n",
      "Client                 : TESCO\n",
      "\n",
      "Environment\t   : Mainframe technologies (COBOL, JCL, VSAM, DB2, SAS, ORACLE, PL-SQL)\n",
      "\n",
      "\n",
      "\n",
      "Description: SAFE is part of IT-Finance. Settlement processing is handled by the Safe system. The purpose of settlement is to confirm the successful processing of a transaction and to obtain payment from the bank. SAFE takes care of settlement. Processes batch Settlement Files to our Acquiring Banks and hold the data for every transaction processed online for 60 days. The files are sent to different banks like RBS, NATWEST, HSBC, AMEX, COMPOWER (ATOS) based on the card type. The banks will process the data and pay funds directly into our Tesco bank account.\n",
      "\n",
      "\n",
      "\n",
      "Cash Reports is a reconciliation system where all the tender related details are recorded and stored in the oracle database tables. All the records will be loaded into Accurate SQL server database and reconciled using FISERV tool named as Accurate. All the reconciled data and data cleared by business user will be reported to General Ledger.\n",
      "\n",
      "\n",
      "\n",
      "Responsibilities:\n",
      "\n",
      "Involve in all phases of software development like Analysis, design, coding, testing for development and enhancement work requests (work orders greater than 500 hours).\n",
      "\n",
      "Participation in requirements gathering meeting with clients.\n",
      "\n",
      "Preparing various reports for client status meeting.\n",
      "\n",
      "Review the estimates for work items, help the team with impact analysis and participate in estimation justification meetings with the clients.\n",
      "\n",
      "Participate in all AGILE SCRUM meetings and update the status of work parcel.\n",
      "\n",
      "Review of all the work artifacts from the team.\n",
      "\n",
      "Providing the test support and fixing all the defects raised.\n",
      "\n",
      "Implementing the changes in production system.\n",
      "\n",
      "Supporting and Monitoring Production batches.\n",
      "\n",
      "Provide maintenance support for the application which includes all the housekeeping Jobs.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Project # 7\n",
      "\n",
      "\n",
      "\n",
      "Project Name\t: Retirement Plans                                               Role   : Software Engineer\n",
      "\n",
      "Duration\t: Sep 2010 – Feb 2011\n",
      "\n",
      "Client   \t:  Fidelity\n",
      "\n",
      "Company\t: Fidelity India Pvt Ltd\n",
      "\n",
      "Environment\t: Mainframe technologies (COBOL, JCL, VSAM, SAS, DB2)\n",
      "\n",
      "\n",
      "\n",
      "Description:  This project is mainly designed to provide benefits to employees for tax exemption and to save money till retirement. Selection of the plan choice is given purely to the employee and employer will share the money based on the plan selection. So as part of this project, we need to pull the reports as per the customer’s demand and sent to the clients at the desired deadline without any delay.\n",
      "\n",
      "\n",
      "\n",
      "Responsibilities:\n",
      "\n",
      "Deliver the reports requested by End users in time without any delay.\n",
      "\n",
      "Taking project related calls and interacting with clients and end users directly.\n",
      "\n",
      "Mentoring new joiners in the project.\n",
      "\n",
      "There are few challenges where in there is a requirement from end users to create the reports in a customized which requires logical change in the program. Able to change the code in a less stipulated time and deliver the reports to the users at the right time without any delay.\n",
      "\n",
      "Automated few reports which reduced manual effort.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Project # 8\n",
      "\n",
      "\n",
      "\n",
      "Project Name\t     : General Ledger Project                            Role    : Application Developer\n",
      "\n",
      "Duration\t     : April 09 – Aug 10\n",
      "\n",
      "Client                   :  WellPoint\n",
      "\n",
      "Company\t     : IBM India Pvt Ltd\n",
      "\n",
      "Environment\t     : Mainframe technologies (COBOL, JCL, VSAM, SAS, DB2)\n",
      "\n",
      "\n",
      "\n",
      "Description:  This project is to post the Administrative services only Group’s billed and unbilled claim level activity to the general ledger. This involves high risk that involves developing complex code, rigorous Unit Testing and Integration Testing. Helped customer in coming up with the requirements by suggesting easiest way to proceed. Worked closely with the Customer and came up with neat schedule and plan for unit testing and integration testing to avoid the risk. Also delivered the code with high quality 1 week earlier than planned date to dependent system and delivered the project without any business impact to Customer. Received very high appreciation from the Customer, Onsite BAM and Delivery Manager. Played key role and lead the project team in Analysis, Design, Unit testing, Test planning, System testing, Regression setup and support, Pre Implementation support, Implementation support.\n",
      "\n",
      "\n",
      "\n",
      "Responsibilities:\n",
      "\n",
      "Responsible for successfully implementing the project without any issues.\n",
      "\n",
      "Successfully handled big releases of the project which helped our client in getting compliance certificate without any Non-compliance.\n",
      "\n",
      "Follow complete SDLC cycle whenever application upgrade takes place – used   Waterfall methodology depending on the complexity and flexibility of the requirement.\n",
      "\n",
      "Have successfully deployed project which gave me an exposure to work on all of these phases - Requirements Gathering, Analysis, Estimation, Designing, Development, and Testing till Implementation. Used all the standards followed in our organization (e.g. OPAL process and templates).\n",
      "\n",
      "Key participant in Quality process for the project\n",
      "\n",
      "Submitting Project Metrics and participating in all Quality processes/audits, project health reviews.\n",
      "\n",
      "Worked on Rational portfolio manager.\n",
      "\n",
      "Taking project related calls and interacting with clients and end users directly.\n",
      "\n",
      "Mentoring new joiners in the project. \n",
      "\n",
      "There was a challenge while implementing the project since it involves feeds across applications. I am able to coordinate across the teams, organize meetings and drill down the solution in very quick turnaround of time.\n",
      "\n",
      "Supporting and Monitoring Production batches.\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "Project # 9\n",
      "\n",
      "\n",
      "\n",
      "Project Name   :  MCS Prompt Pay Project                              Role   : Application Developer\n",
      "\n",
      "Duration\t  :  July 2008 – December 2008\n",
      "\n",
      "Client\t             :  WellPoint\n",
      "\n",
      "Company\t :  IBM India Pvt Ltd\n",
      "\n",
      "Environment\t :   Mainframe technologies (COBOL, JCL, VSAM, SAS, DB2)\n",
      "\n",
      "\n",
      "\n",
      "Description:  \n",
      "\n",
      "New York state mandate to charge all the groups for late fee payment and hence as part of this project Prompt pay amount need to be included as an additional field in the current logic and charge the group this late fee payment. Worked on new design with several modules being developed for this project. As well on Customer’s demand created few reports as well which will help in auditing purposes.\n",
      "\n",
      "\n",
      "Responsibilities:\n",
      "\n",
      "Responsible for successfully implementing the project without any issues.\n",
      "\n",
      "Responsible for successfully implementing the project without any issues.\n",
      "\n",
      "Follow complete SDLC cycle whenever application upgrade takes place\n",
      "\n",
      "Used   Waterfall methodology depending on the complexity and flexibility of the requirement.\n",
      "\n",
      "Have successfully deployed project which gave me an exposure to work on all of these phases Requirements Gathering, Analysis, Estimation, Designing, Development, and Testing till Implementation. Used all the standards followed in our organization (e.g. OPAL process and templates).\n",
      "\n",
      "Analyzing the Functional inputs and estimating the size of the project.\n",
      "\n",
      "Supporting and monitoring production batches.\n",
      "\n",
      "Resolving defects and User queries in production within SLA.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Project  # 10\n",
      "\n",
      "\n",
      "\n",
      "Project Name  :  NPI Contingency Project (National Provider Identifier)\n",
      "\n",
      "Duration          :  July 2007 – December 2007                     \n",
      "\n",
      "Client\t            : WellPoint     \t\t\t\t            Role  : Application Developer\n",
      "\n",
      "Company         : IBM India Pvt Ltd\n",
      "\n",
      "Environment  : Mainframe technologies (COBOL, JCL, VSAM, SAS, DB2)\n",
      "\n",
      "\n",
      "\n",
      "Description:  \n",
      "\n",
      "This project implemented as a contingency to the original NPI project due to US federal mandate requirements allowing the providers the flexibility to send the claims with both Empire provider number and Federal NPI as well. Due to high quality work delivered got appreciations from high level authority.\n",
      "\n",
      "Responsibilities:\n",
      "\n",
      "\tWorked on development requests which involved code changes.\n",
      "\n",
      "\tAnalyzing the Functional inputs and estimating the size of the project.\n",
      "\n",
      "\tPerform unit testing once development and design (technical document) is completed.\n",
      "\n",
      "\tSupporting and monitoring production batches.\n",
      "\n",
      "Resolving defects and User queries in production within SLA.\n",
      "\n",
      "Responsible for successfully implementing the project without any issues.\n",
      "\n",
      "\t\n",
      "\n",
      "\t\n",
      "\n",
      "\tEducation Summary:\n",
      "\n",
      "\t\n",
      "\n",
      "Corporate Post Graduate Diploma from SYMBIOSIS with 71% during 2007-2009.\n",
      "\n",
      "Bachelor of Technology from Jawaharlal Nehru Technological University, Hyderabad with 74.5% in year 2006.\n",
      "\n",
      "10+2 from S.V.S.R Junior College with 95.4% in year 2002\n",
      "SP\n",
      "\n",
      "sandeep pulabarth\n",
      "\n",
      "Lead Engineer @TCS | +91-8722274646\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "SP\n",
      "\n",
      "Objective\n",
      "\n",
      "Apassionatedatascientisthavingexperienceinpredictivemodelling,dataprocessing,anddataminingalgorithmstosolvechallengingbusinessproblems.StrongbackgroundinPythonandknowledgeofvarioustypesofmachinelearning techniques.\n",
      "\n",
      "software tools\n",
      "\n",
      "Jupyter\n",
      "\n",
      "Anaconda\n",
      "\n",
      "Spyder\n",
      "\n",
      "CODING SKILLS\n",
      "\n",
      "Core Python\n",
      "\n",
      "NumPy\n",
      "\n",
      "Pandas\n",
      "\n",
      "Scipy\n",
      "\n",
      "Matplotlib\n",
      "\n",
      "Machine Learning\n",
      "\n",
      "Exposure to \n",
      "\n",
      "Random Forest,\n",
      "\n",
      "Decision tree,\n",
      "\n",
      "KNNs, \n",
      "\n",
      "Adaboost\n",
      "\n",
      "XGBoost\n",
      "\n",
      "Linear Regression\n",
      "\n",
      "Logistic Regression\n",
      "\n",
      "KMeans\n",
      "\n",
      "other skills\n",
      "\n",
      "Statistics\n",
      "\n",
      "Hive\n",
      "\n",
      "SQL\n",
      "\n",
      "Unigraphics NX\n",
      "\n",
      "Teamcenter Engineering\n",
      "\n",
      "PLM/PDM Tools\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Experience\n",
      "\n",
      "LEAD ENGINEER •tcs• jan/2017 – till date\n",
      "\n",
      "Understand the requirements and formulate problem statements.\n",
      "\n",
      "Acquisition and analysis of data.\n",
      "\n",
      "Analyze data sets to provide insights to experts from various domains.\n",
      "\n",
      "Building statistical modeling and applying various machine learning techniques.\n",
      "\n",
      "Use of analytics for automation and enhancement in the field of aerospace industry eg. - predictive maintenance using machine learning\n",
      "\n",
      "Data Understanding and process formation from clients.\n",
      "\n",
      "Extensive hands-on with regression and classification techniques.\n",
      "\n",
      "Building baseline models for the requirements with necessary data preparation.\n",
      "\n",
      "\n",
      "\n",
      "project lead• semconindia pvt ltd • nov/2010 –jan/2017\n",
      "\n",
      "\n",
      "\n",
      "Project 1: After analyzing datasetsfrom various engines built predictive models for high impact Aero-Engine components. This model has not only consistently predicted the failure of components, but also helped reduce the downtime of aircraft in the field.\n",
      "\n",
      "Project 2: Built an integrated spare parts forecasting model for a dealer network of a major OEM. The solution improved traditional forecasting models with the real-time demandfor the spare parts collected from asset performance in the field\n",
      "\n",
      "\n",
      "\n",
      "Mechanical Projects\n",
      "\n",
      "Domain: Steam Turbine, Turbomachinery\n",
      "\n",
      "Client:    Siemens –Finspong, Sweden\n",
      "\n",
      "Tool:      NX6, Catia V5, Teamcenter & Pulse\n",
      "\n",
      "Inputs:   CADDS5 and Turbine 2D Layout.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Responsible for 5 Engineers team working for Siemens steam Turbine-Finspong on Migration and Design & Development. Involved in Migration of CADDS5 drawings to NX and creating Manufacturing drawings for various steam turbine components like casings, Inlet and exhaust bearing, Rotors, diaphragm carriers, Labyrinth seals, Valves, Inlet volutes from Iges, Exhaust casings from 2D layouts\n",
      "\n",
      "\n",
      "\n",
      "Project: Design and Migration of Steam turbine components of SST700/900 from CADDS5 to NXAnd creating Manufacturing drawings from provided Turbine Layouts\n",
      "\n",
      "\n",
      "\n",
      "Roles & Responsibilities:\n",
      "\n",
      " \n",
      "\n",
      "Trained Engineers on NX, Siemens workflow process, Steamturbine components, Team Centre & Pulse\n",
      "\n",
      "Responsible for gathering inputs from Siemens and discussing with HG responsible on improvements and Technical issues before starting work.\n",
      "\n",
      "Work planning and allocating tasks based on skill sets of the engineers.\n",
      "\n",
      "Supporting Team in technical and design issues. \n",
      "\n",
      "Responsible for quality and on-time delivery.\n",
      "\n",
      "Worked on Design & Detailing of various steam turbine components like casings, bearings, rotors, Internal pipes & conn., Exhaust casings, Inlet volute etc.\n",
      "\n",
      "Prepare relevant design and layouts using NX in accordance with appropriate standards and design.\n",
      "\n",
      "Preparing Bill of material specifications for various steam turbine components and creating new structures.\n",
      "\n",
      "Set up new process and checklist to ensure quality output to the client.\n",
      "\n",
      "Reviewing the drawings in customer data base and approving them to next level.\n",
      "\n",
      "\n",
      "\n",
      "SR ENGINEER •infotech (presently CYIENT) • jun/2008 – nov/2010\n",
      "\n",
      "\n",
      "\n",
      "Domain: Aircraft Engine, Aerospace\n",
      "\n",
      "Client: Pratt & Whitney\n",
      "\n",
      "Role: Design Engineer\n",
      "\n",
      "\n",
      "\n",
      "About P&W - Pratt & Whitney was developing a new engine configuration having a geared technology for its Next generation products, PW1000G. According to Pratt & Whitney in engine configuration a new bearing (#6) is to be added. The legacy engines of Pratt consist of only 5 number of bearing compartments. #6 bearing compartment is newly added in PW1000g. Our team was responsible for design of Squirrel cage, Jumper tube, Spacer, End cap and Rear Nozzle. The components should satisfy both Design Criteria and also manufacturing feasibility.\n",
      "\n",
      "\n",
      "\n",
      "Projects involved were\n",
      "\n",
      "\n",
      "\n",
      "Design of #6th Bearing Compartment parts/ PW1000G MRJ\n",
      "\n",
      "Design of Squirrel cage & Detailing\n",
      "\n",
      "Design of Spacer & Detailing\n",
      "\n",
      " Design #4th Bearing Compartment parts/ PW1000G MRJ  \n",
      "\n",
      "Design of Air Deflector & Detailing\n",
      "\n",
      "Sector Cut Models of all Bearing Compartment parts/ PW1000G MRJ\n",
      "\n",
      "Design #1 Bearing Compartment parts/ FT4000\n",
      "\n",
      ".\n",
      "\n",
      "engineer • kabra extrusiontechnik ltd•may/2006 –jun/2008\n",
      "\n",
      "\n",
      "\n",
      "I am involved as a design engineer in processing regular work order along with upgrading of existing extrusion machinery.  \n",
      "\n",
      "My role also demands \n",
      "\n",
      "Design, modelling and drafting of plastic extrusion Machines.\n",
      "\n",
      "Provided total plant layout for assembly purpose.\n",
      "\n",
      "Prepare assembly drawings for assembly purpose.\n",
      "\n",
      "Reverse engineering of the plastic extrusion machinery critical parts.\n",
      "\n",
      "Conversion of collaborator’s Die head drawing from ASME standards to ISO standards.  \n",
      "\n",
      "Process all Tape plant work orders.\n",
      "\n",
      "\n",
      "\n",
      "Education\n",
      "\n",
      "Bachelorof mechanical engineering• 2006 • Gandhi institue of engineering and technology,gunupur\n",
      "\n",
      "You might want to include your GPA and a summary of relevant coursework, awards, and honors.\n",
      "\n",
      "Awards\n",
      "\n",
      "Spot Appreciation Award - 12th May 2016\n",
      "\n",
      "Certiﬁcate of Appreciation - 22nd July 2015\n",
      "\n",
      "Spot Appreciation Award - 29th May 2014\n",
      "\n",
      "Outstanding team performance – November 2008\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sandeep.dasc1@gmail.com\n",
      "\n",
      "https://github.com/sandeepdasc1\n",
      "\n",
      "www.kaggle.com/sandeepdasc1\n",
      "\n",
      "www.linkedin.com/in/pulavarthy-s-321a92152/\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sandeep.dasc1@gmail.com\n",
      "\n",
      "https://github.com/sandeepdasc1\n",
      "\n",
      "www.kaggle.com/sandeepdasc1\n",
      "\n",
      "www.linkedin.com/in/pulavarthy-s-321a92152/\n",
      "\n",
      "2\n",
      "CAREER OBJECTIVE\n",
      "\n",
      "\n",
      "\n",
      "A passionate data scientist having knowledge in predictive modelling, data processing, and data mining algorithms to solve challenging business problems. Strong background in Python and knowledge of various types of machine learning techniques.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "SUMMARY\n",
      "\n",
      "\n",
      "\n",
      "Good understanding of Statistics, Machine learning and deep learning concepts.\n",
      "\n",
      "Hands on experience in python frameworks like scikit-learn ,scipy,numpy\n",
      "\n",
      "Boosting techniques like XGBOOST, PCA.\n",
      "\n",
      "Basic understanding on ML libraries like tensor flow, spark.\n",
      "\n",
      "Data analysis\n",
      "\n",
      "Classification of images using AI convolutional neural network model\n",
      "\n",
      "Data vitalization using MATLAB\n",
      "\n",
      "TECHNICAL SKILLS\n",
      "\n",
      "\n",
      "\n",
      "SKill\n",
      "\n",
      "Technology known\n",
      "\n",
      "Programming /Scripting\n",
      "\n",
      "Python,C,Javascript\n",
      "\n",
      "Tools /IDE\n",
      "\n",
      "Pycharm,Pyspyder,Jupyter Notebook\n",
      "\n",
      "Data Science\n",
      "\n",
      "Machine learning, Data Aritifical Inteiligence,Statistical modelling ,Natural language Processing, Deep learning ,pandas,scikit-learn,keras,matplotlib,Data virtualization Analysi,tensorflow, spark , time series arima model , cnn , RNN , RNN LSTM ,\n",
      "\n",
      "Operating system\n",
      "\n",
      "Windows, Linux\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\tPROFESSIONALEXPERIENCE\n",
      "\n",
      "\n",
      "\n",
      "Altimetrik India Private Limited (Sept 2016 –Till date)\n",
      "\n",
      "\n",
      "\n",
      "Role : System engineer\n",
      "\n",
      "\n",
      "\n",
      "Project 1 : Banking application monitoring.\n",
      "\n",
      "Involved in building an AI predictive modelling for monitoring bank application, it will help in checking the health status and monitoring the interface applications connected with the banking system, it Monitor and raises an alarm if there is any major issues within the application.\n",
      "\n",
      "(Python, Random Forest, Convolutional Neural Networks (CNN), Keras, Tensorflow )\n",
      "\n",
      "Project 2 : Credit and Loan eligiblity score\n",
      "\n",
      "In this project, we built a model for analyzing the credit score and loan eligibility of the customers based on the previous transaction and KYC information with cognitive computing technologies with cross validation set and regression tools while filling the online application.\n",
      "\n",
      "(Python,classification and regression model , neural networks)\n",
      "\n",
      "\n",
      "\n",
      "Wipro Infotech (Dec 2015- Aug 2016)\n",
      "\n",
      "\n",
      "\n",
      "Role: Application Engineer\n",
      "\n",
      "\n",
      "\n",
      "Project : Was involved in designing of chatbot with AI predictive modelling, neural networks  and Machine learning techniques , The bot was used for conversational banking with quick TAT and helped customers with their KYC queries and transaction details in chat.\n",
      "\n",
      "\n",
      "\n",
      "\tEDUCATION\n",
      "\n",
      "\t\n",
      "\n",
      "Bachelor of Engineering  - 2014-2015\n",
      "\n",
      "Tontadarya college of Engineering ,Gadag,Karnataka\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Pre-University college – 2010\n",
      "\n",
      "St.Aloysius PU College ,Harihar,Karnataka\n",
      "\n",
      "\n",
      "\n",
      "\tEDUCATION\n",
      "\n",
      "\t\n",
      "\n",
      "\tSpot Appreciation award – Oct 2017\n",
      "\n",
      "\tCertificate of Appreciation – Mar 2018\n",
      "\n",
      "\tSpot Appreciation Award – Feb 2019\n",
      "Summary\n",
      "\n",
      "3+ years total experience in IT industry in which I have 2+ years of in Machine learning which include predictive modeling, data processing, data mining, Machine Learning algorithms, hands-on experience leveraging machine learning models to solve challenging business problems and 1 year of experience in UCCE and CISCO IPT platform. \n",
      "\n",
      "https://github.com/atharmohammad\n",
      "\n",
      "Experience Summary\n",
      "\n",
      "\n",
      "\n",
      "Involved in Data Preprocessing Techniques for making the data useful for creating Machine Learning models.\n",
      "\n",
      "Translate product requirements into analytical requirements/specification, design and develop required functionality.\n",
      "\n",
      "Involved in creating various regression and classification algorithms by using various sklearn libraries such as Linear Regression, Decision Trees, Naïve Baye’s.\n",
      "\n",
      "Involved in creating a model for predicting the inbound calls for AVIVA, RSA and Barclays using Kernel SVM\n",
      "\n",
      "Involved in clustering of alarms generated by VoIP devices to reach correct team.\n",
      "\n",
      "\t\t\n",
      "\n",
      "Work Experience\n",
      "\n",
      "\n",
      "\n",
      "Vodafone Shared Services \n",
      "\n",
      "DATA Scientist (May 2016 to till date)\n",
      "\n",
      "\n",
      "\n",
      "Project 1:\tPrediction of inbound calls recording \n",
      "\n",
      "Technology used: Kernel SVM\n",
      "\n",
      "Database:\tSQL \n",
      "\n",
      "Summary:All the calls received by the agents are being recorded\n",
      "\n",
      "\t and with the help of Kernel SVM we able to predict the \n",
      "\n",
      "\t\twhen there is issue with the recording servers.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Project 2:\tClustering of alarms generated by various Networking devices\n",
      "\n",
      "Technology used:K-Mean Clustering   \n",
      "\n",
      "Database:\tSQL\n",
      "\n",
      "Summary:Alarms generated by various devices are usually assign\n",
      "\n",
      " with the code and few descriptions. With the help of \n",
      "\n",
      "     K-Mean Clustering the alarm is passed to correct team \n",
      "\n",
      "    for investigation.\n",
      "\n",
      "\n",
      "\n",
      "Vodafone Shared Services \n",
      "\n",
      "VoIP Specialist (May 2015 to May 2016)\n",
      "\n",
      "Involve in designing the UCCE call flow, configuring the gateways and implementing the new changes or new VoIP setups as per the customer requirement.\n",
      "\n",
      "\n",
      "\n",
      "Technical Skills\n",
      "\n",
      "\n",
      "\n",
      "\t\n",
      "\n",
      "Academic Profile\n",
      "\n",
      "\t\n",
      "\n",
      "Level\n",
      "\n",
      "Year of Passing \n",
      "\n",
      "University / Board\n",
      "\n",
      "Percentage\n",
      "\n",
      "Bachelor of Engineering \n",
      "\n",
      "2014\n",
      "\n",
      "Nagpur University \n",
      "\n",
      "68%\n",
      "\n",
      "HSC\n",
      "\n",
      "2010\n",
      "\n",
      "CBSE\n",
      "\n",
      "75.67%\n",
      "\n",
      "SSC\n",
      "\n",
      "2008\n",
      "\n",
      "CBSE\n",
      "\n",
      "79.6%\n",
      "\n",
      "\t\t\n",
      "\n",
      "\n",
      "\n",
      "Personal Details\n",
      "\n",
      "\n",
      "\n",
      "Fathers Name\t\t:  Muniswamy Naidu\t\t\n",
      "\n",
      "Nationality\t\t:  Indian     \n",
      "\n",
      "Gender\t\t\t:  Male\n",
      "\n",
      "Date of Birth\t\t:  17-Jun-1991\t\n",
      "\n",
      "Languages\t\t:  English and Hindi\n",
      "\n",
      "Address\t\t: Lalpeth colony DSM 24, Chandrapur , Maharashtra\n",
      "RESUME\n",
      "\n",
      "\n",
      "\n",
      "SUMMARY\n",
      "\n",
      "Data Scientist with Master in Computer Engineering and 4+ years of experience using predictive modeling, data processing, data mining algorithms, computer vision , natural language processing , hands-on experience leveraging machine learning, deep \t learning ,transfer learning  models to solve challenging business problems.\n",
      "\n",
      "Job Responsibility \n",
      "\n",
      "\t\t\tAchievement-driven professional with an experience of  4 years.\n",
      "\n",
      "\t\t\tExperience in building applications with Artificial Intelligence, Machine Learning, Deep Learning, Recurrent Neural Network ,Computer vision , NLP and Python .\n",
      "\n",
      "\t\t\tBuilt various computer vision system for Real time surveillance, smart parking check post , Virtual banking . \n",
      "\n",
      "\t\t\tWorked on Deployment and optimizationof various computer vision, Machine learning and NLP solution on web based application ,Azure platform using kubernetes services and Raspberry pi . \n",
      "\n",
      "\t\t\tDesigning the neural networks using Tensorflow for various internal projects within the company and working on Chatbots using NLP.\n",
      "\n",
      "Technical Skill:\n",
      "\n",
      "Skill\n",
      "\n",
      "Technology worked on\n",
      "\n",
      "Domain\n",
      "\n",
      "Investment Banking\n",
      "\n",
      "Programming/Scripting\n",
      "\n",
      "Python,Java\n",
      "\n",
      "Tools/IDE\n",
      "\n",
      "pycharm,Pyspyder,Jupyter  Notebook, Eclipse\n",
      "\n",
      "Cloud\n",
      "\n",
      "GAIA ( Pivotal Cloud Foundry )\n",
      "\n",
      "Machine learning \n",
      "\n",
      "Machine Learning,Data Analysis, Artificial intelligence, Natural Language Processing,pandas,scikit learn,matplotlib,python,Data Cleaning\n",
      "\n",
      "Deep Learning/Computer vision \n",
      "\n",
      "Tensorflow, keras,CNN,faster CNN, RNN, RNN – LSTM, Vgg16,Resnet-50, Mobilenet, SSD,Harcascade,Tensorflow JS \n",
      "\n",
      "Project Methodology\n",
      "\n",
      "Agile SCRUM\n",
      "\n",
      "Operating Systems\n",
      "\n",
      "Windows, Cent OS , Red Hat, Ubuntu\n",
      "\n",
      "Distribution\n",
      "\n",
      "Cloudera\n",
      "\n",
      "Hardware\n",
      "\n",
      "Nvidiatesla,Raspberry pi 3b+ \n",
      "\n",
      "\n",
      "\n",
      "Version Control\n",
      "\n",
      "GIT, BIT BUCKET\n",
      "\n",
      "Professional Experience \n",
      "\n",
      "Project-1\n",
      "\n",
      "CLIENT: J P Morgan Chase\n",
      "\n",
      "\n",
      "\n",
      "Project Name\n",
      "\n",
      "Sparkle Innovation Team\n",
      "\n",
      "Start Date\n",
      "\n",
      "July 2018\n",
      "\n",
      "Owner\n",
      "\n",
      "J P Morgan Chase\n",
      "\n",
      "End Date\n",
      "\n",
      "Till Date\n",
      "\n",
      "Project Location\n",
      "\n",
      "Bangalore – India\n",
      "\n",
      "           Team Size \n",
      "\n",
      "24\n",
      "\n",
      "\n",
      "\n",
      "Project Description:\n",
      "\n",
      "I am working as a Senior Software Engineer with Mphasis for J P Morgan client inSparkle Innovation Team. In this  engagement I am working as a Developer for Machine learning and computer vision use cases so far I have involved  multiple use cases in like Traders Monitoring system , surveillance system for employees (Smart Parking Check Post) and may projects are in pipeline  . \n",
      "\n",
      "\n",
      "\n",
      "Environment & technology used :Machine learning algorithms , Computer Vision , Deep leaning algorithms, Raspberry pi , GAIA, Nvidia tesla k80 . \n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\n",
      "\n",
      "Contribution:\n",
      "\n",
      "Involved in Requirement gathering with various clients for various use case and Feasibility check for all the requirement with timeline. \n",
      "\n",
      "\t\t\tWorking closely with business and engineering teams to encourage statistical best practices with respect to experimental design, data capture and data analysis.\n",
      "\n",
      "Working in collaboration with Product Managers to understand the challenges towards a product development and provide a solution with ML and AI techniques.\n",
      "\n",
      "\t\t\t\n",
      "\n",
      "\t\t\tParticipating in Data Preprocessing Techniques in order to make data useful for creating Machine Learning Models\n",
      "\n",
      "Building baseline models for the requirements with necessary data preparation.\n",
      "\n",
      "Parameter tuning process for optimal model hyperparameters.\n",
      "\n",
      "\n",
      "\n",
      "\t\t\tHighlights:\n",
      "\n",
      "\t\t\tRecognized by managers, colleagues, and peers for innovation, communication, and teamwork to ensure quality, timely project completion.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Project-2\n",
      "\n",
      "CLIENT:  J P Morgan Chase\n",
      "\n",
      "\n",
      "\n",
      "Project Name\n",
      "\n",
      "COIN ( Contract Intelligence )\n",
      "\n",
      "Start Date\n",
      "\n",
      "January  2017\n",
      "\n",
      "Owner\n",
      "\n",
      "J P Morgan Chase\n",
      "\n",
      "End Date\n",
      "\n",
      "June 2018\n",
      "\n",
      "Project Location\n",
      "\n",
      "Bangalore – India\n",
      "\n",
      "           Team Size \n",
      "\n",
      "25\n",
      "\n",
      "\n",
      "\n",
      "Project Description:\n",
      "\n",
      "J P Morgan Chase is the biggest bank in the United States. It is one of the largest employers in the American banking sector, with more than 240,000 serving millions of customers. Some of those employees are lawyers and loan officers who spend a total of 360,000 hours each year tackling a slew of rather mundane tasks, such as interpreting commercial-loan agreements. Now, the company has managed to cut the time spent on this work down to a matter of seconds using machine learning.\n",
      "\n",
      "Contract Intelligence runs on a machine learning system that’s powered by a new private cloud network that the bank uses. Apart from shortening the time it takes to review documents, COIN has also managed to help JP Morgan decrease its number of loan-servicing mistakes\n",
      "\n",
      "\n",
      "\n",
      "Environment & technology used : Python,Machine learning, OCR, Transfer Learning, Kafka, cloudera,GAIA\n",
      "\n",
      "\t\t\t\n",
      "\n",
      "Contribution:\n",
      "\n",
      "Involved in requirement gathering and Architecture design of the project for machine learning implementation. \n",
      "\n",
      "Artificial intelligence convolution neural network model to classify images of different objects.\n",
      "\n",
      "Develop statistical models for various predictive methods such as forecasting, classification and regression.\n",
      "\n",
      "Building baseline models for the requirements with necessary data preparation.\n",
      "\n",
      "Parameter tuning process for optimal model hyperparameters.\n",
      "\n",
      "\n",
      "\n",
      "\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Project-3\n",
      "\n",
      "CLIENT:  J P Morgan Chase\n",
      "\n",
      "\n",
      "\n",
      "Project Name\n",
      "\n",
      "Virtual Assistance 2.0\n",
      "\n",
      "Start Date\n",
      "\n",
      "January  2016\n",
      "\n",
      "Owner\n",
      "\n",
      "J P Morgan Chase\n",
      "\n",
      "End Date\n",
      "\n",
      "November 2016\n",
      "\n",
      "Project Location\n",
      "\n",
      "Bangalore – India\n",
      "\n",
      "           Team Size \n",
      "\n",
      "25\n",
      "\n",
      "\n",
      "\n",
      "Project Description:\n",
      "\n",
      "Assistance 2.0 enabled by Alexa Voice Service (AVS), Amazon’s intelligent voice recognition and natural language understanding service that allows ‘s our Retail Banking customers who are having 1000’s accounts to interact with Alexa and get assistance with respect to their account quires instead of navigating through 1200 pages which is big overhead.\n",
      "\n",
      "\n",
      "\n",
      "Environment & technology used : Python,Alexa skillset , Kafka, cloudera ,GAIA\n",
      "\n",
      "\t\t\t\n",
      "\n",
      "Contribution:\n",
      "\n",
      "Involved in requirement gathering and Architecture design of the project for machine learning implementation. \n",
      "\n",
      "Creating Alexa Skill sets and integrating with Alexa.\n",
      "\n",
      "Working in collaboration with Product Managers to understand the challenges towards a product development.\n",
      "\n",
      "Participating in Data Pre-processing Techniques in order to make data useful.\n",
      "\n",
      "Parameter tuning process for optimal model hyperparameters.\n",
      "\n",
      "\n",
      "\n",
      "\t\n",
      "\n",
      "\n",
      "\n",
      "Project-4\n",
      "\n",
      "CLIENT:  J P Morgan Chase\n",
      "\n",
      "\n",
      "\n",
      "Project Name\n",
      "\n",
      "Trade team\n",
      "\n",
      "Start Date\n",
      "\n",
      "June  2015\n",
      "\n",
      "Owner\n",
      "\n",
      "J P Morgan Chase\n",
      "\n",
      "End Date\n",
      "\n",
      "December 2015\n",
      "\n",
      "Project Location\n",
      "\n",
      "Bangalore – India\n",
      "\n",
      "           Team Size \n",
      "\n",
      "16\n",
      "\n",
      "\n",
      "\n",
      "Project Description:\n",
      "\n",
      "We as a team built a machine learning model which is capable of predicting Interest rates of market. Trading decisions was automated based on this model which is build using 1250 features and trained over 3 million records. We still have human resources for supervising the trades made by this model. We have already reached 4.6 billion worth trading.\n",
      "\n",
      "\n",
      "\n",
      "Environment & technology used : Machine learning algorithms, Cloudera , GAIA , Nvidia tesla k80\n",
      "\n",
      "\t\t\t\n",
      "\n",
      "Contribution:\n",
      "\n",
      "Involved in requirement gathering and Architecture design of the project for machine learning implementation. \n",
      "\n",
      "\t\t\tParticipating in Data Preprocessing Techniques in order to make data useful for creating Machine Learning Models.\n",
      "\n",
      "\t\t\tDevelop statistical models for various predictive methods such as forecasting, classification and regression.\n",
      "\n",
      "\t\t\tPerform feature engineering to know the feature importance.\n",
      "\n",
      "\t\t\tBuilding baseline models for the requirements with necessary data preparation.\n",
      "\n",
      "\t\t\tParameter tuning process for optimal model hyper parameters\n",
      "\n",
      "\n",
      "\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "Education\n",
      "\n",
      "Exam / Degree\n",
      "\n",
      "University\n",
      "\n",
      "School / College\n",
      "\n",
      "Year of Passing\n",
      "\n",
      "Percentage / CGPA\n",
      "\n",
      "BE (Computer Science and Engineering)\n",
      "\n",
      "VTU, Karnataka\n",
      "\n",
      "Sapthagiri College of Engineering, Bengaluru.\n",
      "\n",
      "   2014\n",
      "\n",
      "68%\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "5\n",
      "RESUME\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Summary:\n",
      "\n",
      "Data Scientist with Master in Computer Engineering 7+ Years of Experience in Software Development and Web Analytics Implementation and 3+ years of Experience Using Predictive Modelling, Data Processing, DataMining Algorithms,Natural language processing(NLP), hands-on experience leveraging machine learning, Deep Learning Models to Solve Challenging Business Problems.\n",
      "\n",
      "\n",
      "\n",
      "Job Responsibility:\n",
      "\n",
      "Achievement-Driven Professional withaRelevant Experience of 3+ Years.\n",
      "\n",
      "Deep involvement in handling the Critical Deliverables, Benchmarking Solutions, Driving Key Metrics, Maintaining Productivity and ensuring Projects are Profitable.\n",
      "\n",
      "Experience in Statistics, Machine Learning & NLP and Python Methodologies.\n",
      "\n",
      "Experience in Visualization Tools Like Tableau Software, GoogleAnalytics, Adobe Analytics\n",
      "\n",
      "To understand the business use cases from clients and convert them into a well-defined problem statement and explain it to the development team.\n",
      "\n",
      "To Develop Algorithms and Predictive Models to Drive Insights and Business Values from Data\n",
      "\n",
      "To identify data sets required to develop predictive models for solving internal and external business problems\n",
      "\n",
      "Identify and implement use cases which might help the organization business development To interpret results and produce actionable business insights that \n",
      "\n",
      "lead to measurable business and consumer experience performance improvements\t\n",
      "\n",
      "Experience in building applications with Artificial Intelligence, Machine Learning, Deep Learning, Recurrent Neural Network, Computervision, NLP and Python.\n",
      "\n",
      "Worked on Deployment and optimization of various computer vision, Machine learning and NLP solution on web based application, Azure platform using kubernetes services and Raspberry pi. \n",
      "\n",
      "Designing the neural networks using Tensor flow for various internal projects within the company and working on Chatbots using NLP\n",
      "\n",
      "\n",
      "\n",
      "Technical Skills:\n",
      "\n",
      "Skill\n",
      "\n",
      "Technology worked on\n",
      "\n",
      "Domain\n",
      "\n",
      "Marketing Analytics\n",
      "\n",
      "Programming/Scripting\n",
      "\n",
      "Python, JS\n",
      "\n",
      "Tools/IDE\n",
      "\n",
      "Pycharm, Pyspyder, Jupyter  Notebook, Eclipse\n",
      "\n",
      "Cloud\n",
      "\n",
      "Google Cloud,Azure,AWS,GAIA ( Pivotal Cloud Foundry )\n",
      "\n",
      "Machine learning \n",
      "\n",
      "Machine Learning,Data Analysis, Artificial intelligence, Natural Language Processing, Pandas, Scikit learn, Matplotlib, Python, Data Cleaning\n",
      "\n",
      "Deep Learning/Computer vision \n",
      "\n",
      "Tensorflow, keras, CNN, Faster CNN, RNN, RNN – LSTM, Vgg16, Resnet-50, Mobilenet, SSD, Harcascade, Tensorflow JS \n",
      "\n",
      "Project Methodology\n",
      "\n",
      "Agile SCRUM\n",
      "\n",
      "Operating Systems\n",
      "\n",
      "Windows, Ubuntu\n",
      "\n",
      "Distribution\n",
      "\n",
      "Cloudera \n",
      "\n",
      "Hardware\n",
      "\n",
      "Nvidia Tesla,Raspberry Pi 3b+ \n",
      "\n",
      "Version Control\n",
      "\n",
      "GIT, BIT BUCKET\n",
      "\n",
      "Data Base\n",
      "\n",
      "SQL,My SQL\n",
      "\n",
      "\n",
      "\n",
      "\tSkils and Knowledge Areas:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Development Tools\n",
      "\n",
      "Expertise\n",
      "\n",
      "Experience in Years\n",
      "\n",
      "Python Programming\n",
      "\n",
      "Expert\n",
      "\n",
      "3+ Years\n",
      "\n",
      "Machine Learning\n",
      "\n",
      "Expert\n",
      "\n",
      "3+ Years\n",
      "\n",
      "NLP – Natural Language Processing\n",
      "\n",
      "Expert\n",
      "\n",
      "3+ Years\n",
      "\n",
      "Data Visualization\n",
      "\n",
      "Expert\n",
      "\n",
      "3+ Years\n",
      "\n",
      "MYSQL\n",
      "\n",
      "Expert\n",
      "\n",
      "3+ Years\n",
      "\n",
      "AGILE, SCRUM Based Development\n",
      "\n",
      "Expert\n",
      "\n",
      "3+ Years\n",
      "\n",
      "Deep Learning\n",
      "\n",
      "Intermediate\n",
      "\n",
      "1+ Years\n",
      "\n",
      "Big Data\n",
      "\n",
      "Intermediate\n",
      "\n",
      "1+ Years\n",
      "\n",
      "Computer Vision\n",
      "\n",
      "Intermediate\n",
      "\n",
      "1+ Years\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Tools and Libraries Used:\n",
      "\n",
      "\n",
      "\n",
      "Numpy\n",
      "\n",
      "Pandas\n",
      "\n",
      "Stats Models\n",
      "\n",
      "Scipy\n",
      "\n",
      "Seaborn\n",
      "\n",
      "Matplotlib\n",
      "\n",
      "Scikit-learn\n",
      "\n",
      "Jupyter Notebooks\n",
      "\n",
      "Google Colab\n",
      "\n",
      "NLTK\n",
      "\n",
      "Tensorflow\n",
      "\n",
      "Keras\n",
      "\n",
      "Open CV\n",
      "\n",
      "TextBlob\n",
      "\n",
      "Tweepy\n",
      "\n",
      "Gensim\n",
      "\n",
      "Spacy\n",
      "\n",
      "BeautifulSoup\n",
      "\n",
      "\n",
      "\n",
      "Educational Summary:\n",
      "\n",
      "\n",
      "\n",
      "MBA from NIBM (National Institute of Business Management), Chennai with 84.19% (2017-2018) Tamil Nadu \n",
      "\n",
      "BCA from Bishop Heber College (Autonomous) Trichy with 64.17% (2004-2007) Tamil Nadu.\n",
      "\n",
      "\n",
      "\n",
      "Professional Experience:\n",
      "\n",
      "\n",
      "\n",
      "\t\tAssociatedwithZinavo Technologies-Bangalore2012 to Till Now\n",
      "\n",
      "Zinavo Technologies, an ISO 9001-2008 certified company, extending its services in Software & IT Development Company in Bangalore, India\n",
      "\n",
      "\t\tData Scientist From March 2016 to Till Now-3+ Years\n",
      "\n",
      "\t\tDigital Analytics Consultant From April 2014-March -2016-2 Year\n",
      "\n",
      "\t\tDigital Marketing Engineer From April 2012 –March-2014- 2 Years\n",
      "\n",
      "\n",
      "\n",
      "Accountabilities:\n",
      "\n",
      "Core Python,Numpy,Pandas,Matplotlib,SCIKIT Learn, Tensor flow, Tableau\n",
      "\n",
      "Selecting features, building and optimizing classifiers using machine learning techniques\n",
      "\n",
      "Data mining using state-of-the-art methods\n",
      "\n",
      "Extending company’s data with third party sources of information when needed\n",
      "\n",
      "Enhancing data collection procedures to include information that is relevant for building analytic systems\n",
      "\n",
      "Processing, cleansing, and verifying the integrity of data used for analysis\n",
      "\n",
      "Doing ad-hoc analysis and presenting results in a clear manner\n",
      "\n",
      "Creating automated anomaly detection systems and constant tracking of its performance\n",
      "\n",
      "\n",
      "\n",
      "Projects Summary:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Client Name\n",
      "\n",
      "Project Title\n",
      "\n",
      "Technology\n",
      "\n",
      "Roles\n",
      "\n",
      "Durations\n",
      "\n",
      "Zinavo\n",
      "\n",
      "Customer Sales Predictions&Chat Bots Development\n",
      "\n",
      "Google Add Click Predictions\n",
      "\n",
      "Keywords Analysis\n",
      "\n",
      "Python \n",
      "\n",
      "Machine Learning\n",
      "\n",
      "Data Visualization\n",
      "\n",
      "Microsoft Luis\n",
      "\n",
      "Dialog flow\n",
      "\n",
      "NLP\n",
      "\n",
      "Google Cloud\n",
      "\n",
      "PredictiveModelling\n",
      "\n",
      "Data Scientist\n",
      "\n",
      "On Going\n",
      "\n",
      "Altius Hospitals\n",
      "\n",
      "Analysis of the Medical Records of individual’s Lung Capacity\n",
      "\n",
      "Python \n",
      "\n",
      "Machine Learning\n",
      "\n",
      "Data Visualization\n",
      "\n",
      "Matplotlib\n",
      "\n",
      "Data Scientist\n",
      "\n",
      "On Going\n",
      "\n",
      "Tshirt Loot\n",
      "\n",
      "Sentiment Analytics\n",
      "\n",
      "Python\n",
      "\n",
      "Naïve Bayes Algorithm\n",
      "\n",
      "NLP\n",
      "\n",
      "Data Scientist\n",
      "\n",
      "2017-2018\n",
      "\n",
      "Tripath Logistics\n",
      "\n",
      "Transportation Supply Chain \n",
      "\n",
      " Management System\n",
      "\n",
      "\n",
      "\n",
      "Python \n",
      "\n",
      "Machine Learning\n",
      "\n",
      "Data Visualization\n",
      "\n",
      "Matplotlib\n",
      "\n",
      "Data Scientist\n",
      "\n",
      "On Going\n",
      "\n",
      "PRO FX \n",
      "\n",
      "Market Basket Analysis\n",
      "\n",
      "Python \n",
      "\n",
      "Machine Learning\n",
      "\n",
      "Data Visualization\n",
      "\n",
      "Matplotlib\n",
      "\n",
      "Data Scientist\n",
      "\n",
      "2017-2018\n",
      "\n",
      "Magical Nest Interior Designs Pvt.Ltd.\n",
      "\n",
      "Ecommerce Products Recommendation System\n",
      "\n",
      "Python \n",
      "\n",
      "Machine Learning\n",
      "\n",
      "Data Visualization\n",
      "\n",
      "Matplotlib\n",
      "\n",
      "Data Scientist\n",
      "\n",
      "2017-2018\n",
      "\n",
      "POC\n",
      "\n",
      "Classification Problem \n",
      "\n",
      "\n",
      "\n",
      "Python \n",
      "\n",
      "Keras, Pandas, Numpy\n",
      "\n",
      "Data Scientist\n",
      "\n",
      "2+ Years\n",
      "\n",
      "POC\n",
      "\n",
      "Object Detection\n",
      "\n",
      "Deep Learning\n",
      "\n",
      "Data Scientist\n",
      "\n",
      "2+ Years\n",
      "\n",
      "POC\n",
      "\n",
      "Human Activity Recognition using Machine Learning\n",
      "\n",
      "Algorithms : Logistic Regression, KNeighborsClassifier, RandomForestClassifier \n",
      "\n",
      "\n",
      "\n",
      "Data Scientist\n",
      "\n",
      "2+ Years\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Declaration:\n",
      "\n",
      "I hereby declare that the above information is true and correct to the best of my knowledge and belief.\n",
      "\n",
      "PLACE: Bangalore\t\t\t\t\t\t\t\tYours Faithfully\n",
      "\n",
      "DATE:  \t\t\t\t\t\t\t\t\t(R.Nazar) \n",
      "\n",
      "\tTHANK YOU\n"
     ]
    }
   ],
   "source": [
    "github_url=[]\n",
    "for i in (path):\n",
    "    text2=docx2txt.process(r\"Resumes/\"+i)\n",
    "    print(text2)\n",
    "    if (len(re.findall(\"\\w{4,5}[:][\\/][\\/]\\w+[\\.]\\w{3}[\\/]\\w+\",text2)))>0:\n",
    "        github_url_found=(re.findall(\"\\w{4,5}[:][\\/][\\/]\\w+[\\.]\\w{3}[\\/]\\w+\",text2))\n",
    "        if (len(github_url_found)>1):\n",
    "            del(github_url_found[1])\n",
    "            github_url.extend(github_url_found)\n",
    "        else:\n",
    "            github_url.extend(github_url_found)\n",
    "\n",
    "    else:\n",
    "        github_url.append(np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(github_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/sandeepdasc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://github.com/sandeepdasc1', 'https://github.com/sandeepdasc1']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(\"\\w{4,5}[:][\\/][\\/]\\w+[\\.]\\w{3}[\\/]\\w+\",text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame([gmail_id,linkedin_id,github_url],index=['gmail_id','linkedin_id','github_url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gmail_id</th>\n",
       "      <th>linkedin_id</th>\n",
       "      <th>github_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sandeep.dasc1@gmail.com</td>\n",
       "      <td>www.linkedin.com/in/pulavarthy-s-321a92152/</td>\n",
       "      <td>https://github.com/sandeepdasc1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/atharmohammad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  gmail_id                                  linkedin_id  \\\n",
       "0                      NaN                                          NaN   \n",
       "1  sandeep.dasc1@gmail.com  www.linkedin.com/in/pulavarthy-s-321a92152/   \n",
       "2                      NaN                                          NaN   \n",
       "3                      NaN                                          NaN   \n",
       "4                      NaN                                          NaN   \n",
       "5                      NaN                                          NaN   \n",
       "\n",
       "                         github_url  \n",
       "0                               NaN  \n",
       "1   https://github.com/sandeepdasc1  \n",
       "2                               NaN  \n",
       "3  https://github.com/atharmohammad  \n",
       "4                               NaN  \n",
       "5                               NaN  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
